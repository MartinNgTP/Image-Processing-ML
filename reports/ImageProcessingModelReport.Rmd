---
title: "Image Processing Models Report"
author: "Data Science Three Co."
date: "14-11-2024"
output: html_document
---

```{r include=FALSE}
rm(list = ls())
```

```{r setup, include=FALSE}
set.seed(72)
knitr::opts_chunk$set(echo = TRUE, comment="", warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=55))
```

## Introduction {.tabset}

This report explores the performance of various machine learning models applied to the MNIST Fashion dataset. Each model is evaluated based on accuracy, runtime, and an aggregate score calculated using a custom scoring function. The goal is to identify the best-performing model for this image classification task. Ten models were implemented, ranging from traditional algorithms such as K-Nearest Neighbors (KNN) and Classification Trees to advanced techniques like XGBoost and Neural Networks.

The performance of each model was assessed across different sample sizes (2500, 5000, and 10000) and averaged over three iterations. This approach provides insights into how sample size impacts model accuracy and runtime, as well as the suitability of each model for this classification task.

### Setup Code

Please see the code below that loads in the necessary libraries and data, along with constants and variables used. 

```{r libraries}
library(data.table)
library(DT)
library(class) # For KNN
library(rpart) # For Classification Tree
library(e1071) # For SVM
library(nnet) # For Multinomial logistic regression and Neural Networks
library(randomForest) # For RF
library(xgboost) # For XG boost
library(glmnet) # For elastic net 
library(knitr) # for nice tables
library(dplyr)
library(magrittr)
```

```{r source_files}

```

```{r functions}
# Scoring Function
calculate_score <- function(A, B, C) {
  return(0.15 * A + 0.1 * B + 0.75 * C)
}

```

```{r constants}
n.values <- c(2500, 5000, 10000)
iterations <- 3
total_train_size <- 60000      # Total number of rows in training data
hour <- 60      #  To calculate runtime
dp <- 4      # Decimal Places
rf_ntree <- 100 # RF ntree
rf_ntree2 <- 500 # RF ntree
xgboost_max_depth <- 6 # xgboost max depth 
xgboost_eta <- 0.3 # xgboost eta
xgboost_nrounds <- 100 # xgboost nrounds
```

```{r load_data}
train <- fread("data/MNIST-fashion training set-49.csv", verbose = F)
test <- fread("data/MNIST-fashion testing set-49.csv", verbose = F)
```

```{r clean_data}
# Convert label to a factor in both training and test data
train$label <- as.factor(train$label)
test$label <- as.factor(test$label)

# Separate features and labels for the test set
test_features <- as.data.frame(test[, -1, with = FALSE]) # Convert to data frame for compatibility with SVM and Tree
test_labels <- test$label
```

```{r variables}
# Initialize a data frame to store results
scoreboard <- data.frame(
  Model = character(),
  Sample_Size = integer(),
  Data = character(),
  A = numeric(),
  B = numeric(),
  C = numeric(),
  Points = numeric(),
  stringsAsFactors = FALSE
)
```

```{r generate_samples, include=FALSE}
# this is done within each model
```

### Model 1: KNN

The KNN algorithm is a simple yet effective model that classifies an instance based on the majority class among its k-nearest neighbors. Here, we set k=5 to balance accuracy and runtime efficiency.

```{r code_model1_development, eval = TRUE}
# Set the number of neighbors
k <- 5
# KNN 
# Function to train and evaluate KNN
run_knn <- function(sample_data, k = 5) {
  train_features <- as.matrix(sample_data[, -1, with = FALSE])
  train_labels <- sample_data$label
  
  # Measure runtime for KNN
  start_time <- Sys.time()
  knn_predictions <- knn(train = train_features, test = as.matrix(test_features), cl = train_labels, k = k)
  runtime <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  
  # Calculate accuracy and misclassification rate
  accuracy <- mean(knn_predictions == test_labels)
  return(list(accuracy = accuracy, runtime = runtime))
}
```

```{r load_model1}
for (n in n.values) {
  for (i in 1:iterations) {
    sample_data <- train[sample(.N, n)]
    result <- run_knn(sample_data, k)
    accuracy <- result$accuracy
    runtime <- result$runtime
    
    A <- n / total_train_size
    B <- min(1, runtime / hour)
    C <- 1 - accuracy
    points <- calculate_score(A, B, C)
    
    scoreboard <- rbind(scoreboard, data.frame(
      Model = "KNN",
      Sample_Size = n,
      Data = paste("dat", n, i, sep = "_"),
      A = round(A, dp),
      B = round(B, dp),
      C = round(C, dp),
      Points = round(points, dp)
    ))
  }
}
```

### Model 2: Classification Tree

Classification Trees are interpretable models that recursively partition the data based on feature values, aiming to maximize class separation at each split. This method is fast but may suffer from overfitting in complex datasets.

```{r code_model2_development, eval = TRUE}
# Classification Tree
# Function to train and evaluate Classification Tree
run_classification_tree <- function(sample_data) {
  sample_data <- as.data.frame(sample_data)
  
  # Measure runtime for Classification Tree
  start_time <- Sys.time()
  tree_model <- rpart(label ~ ., data = sample_data, method = "class")
  tree_predictions <- predict(tree_model, newdata = test_features, type = "class")
  runtime <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  
  # Calculate accuracy and misclassification rate
  accuracy <- mean(tree_predictions == test_labels)
  return(list(accuracy = accuracy, runtime = runtime))
}

```

```{r load_model2}
for (n in n.values) {
  for (i in 1:iterations) {
    sample_data <- train[sample(.N, n)]
    result <- run_classification_tree(sample_data)
    accuracy <- result$accuracy
    runtime <- result$runtime
    
    A <- n / total_train_size
    B <- min(1, runtime / hour)
    C <- 1 - accuracy
    points <- calculate_score(A, B, C)
    
    scoreboard <- rbind(scoreboard, data.frame(
      Model = "Classification Tree",
      Sample_Size = n,
      Data = paste("dat", n, i, sep = "_"),
      A = round(A, dp),
      B = round(B, dp),
      C = round(C, dp),
      Points = round(points, dp)
    ))
  }
}
```

### Model 3: SVM, cost = 1

An SVM aims to find the hyperplane that best separates classes. With a linear kernel and a cost parameter of 1, this model is tuned for balanced performance between margin width and misclassification.

```{r code_model3_development, eval = TRUE}
# SVM
# Function to train and evaluate SVM
run_svm <- function(sample_data, cost = 1, kernel = "linear") {
  sample_data <- as.data.frame(sample_data)
  sample_data$label <- as.factor(sample_data$label)
  
  # Measure runtime for SVM
  start_time <- Sys.time()
  svm_model <- svm(label ~ ., data = sample_data, kernel = kernel, cost = cost)
  svm_predictions <- predict(svm_model, newdata = test_features)
  runtime <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  
  # Calculate accuracy and misclassification rate
  accuracy <- mean(svm_predictions == test_labels)
  return(list(accuracy = accuracy, runtime = runtime))
}

```

```{r load_model3}
for (n in n.values) {
  for (i in 1:iterations) {
    sample_data <- train[sample(.N, n)]
    result <- run_svm(sample_data, cost = 1, kernel = "linear")
    accuracy <- result$accuracy
    runtime <- result$runtime
    
    A <- n / total_train_size
    B <- min(1, runtime / hour)
    C <- 1 - accuracy
    points <- calculate_score(A, B, C)
    
    scoreboard <- rbind(scoreboard, data.frame(
      Model = "SVM, cost 1",
      Sample_Size = n,
      Data = paste("dat", n, i, sep = "_"),
      A = round(A, dp),
      B = round(B, dp),
      C = round(C, dp),
      Points = round(points, dp)
    ))
  }
}
```

### Model 4: SVM, cost = 10

To examine the impact of a higher cost on the SVM's performance, we set the cost parameter to 10. This model prioritizes classification accuracy over margin width, potentially reducing misclassification at the expense of runtime.

```{r code_model4_development, eval = TRUE}
# SVM
# Function to train and evaluate SVM
run_svm <- function(sample_data, cost = 1, kernel = "linear") {
  sample_data <- as.data.frame(sample_data)
  sample_data$label <- as.factor(sample_data$label)
  
  # Measure runtime for SVM
  start_time <- Sys.time()
  svm_model <- svm(label ~ ., data = sample_data, kernel = kernel, cost = cost)
  svm_predictions <- predict(svm_model, newdata = test_features)
  runtime <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  
  # Calculate accuracy and misclassification rate
  accuracy <- mean(svm_predictions == test_labels)
  return(list(accuracy = accuracy, runtime = runtime))
}

```

```{r load_model4, include=FALSE}
for (n in n.values) {
  for (i in 1:iterations) {
    sample_data <- train[sample(.N, n)]
    result <- run_svm(sample_data, cost = 10, kernel = "linear")
    accuracy <- result$accuracy
    runtime <- result$runtime
    
    A <- n / total_train_size
    B <- min(1, runtime / hour)
    C <- 1 - accuracy
    points <- calculate_score(A, B, C)
    
    scoreboard <- rbind(scoreboard, data.frame(
      Model = "SVM, cost 10",
      Sample_Size = n,
      Data = paste("dat", n, i, sep = "_"),
      A = round(A, dp),
      B = round(B, dp),
      C = round(C, dp),
      Points = round(points, dp)
    ))
  }
}
```

### Model 5: Neural Networks

Neural Networks, particularly with a single hidden layer of ten neurons, capture complex patterns in the data. However, training time can increase significantly with sample size and complexity.

```{r code_model5_development, eval = TRUE}

# Function to train and evaluate Neural Network
run_neural_net <- function(sample_data, size = 10) {
  sample_data <- as.data.frame(sample_data)
  
  # Measure runtime for Neural Network
  start_time <- Sys.time()
  nn_model <- nnet(label ~ ., data = sample_data, size = size, maxit = 200, trace = FALSE)
  nn_predictions <- predict(nn_model, newdata = test_features, type = "class")
  runtime <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  
  # Calculate accuracy and misclassification rate
  accuracy <- mean(nn_predictions == test_labels)
  return(list(accuracy = accuracy, runtime = runtime))
}

```

```{r load_model5}
for (n in n.values) {
  for (i in 1:iterations) {
    sample_data <- train[sample(.N, n)]
    result <- run_neural_net(sample_data)
    accuracy <- result$accuracy
    runtime <- result$runtime
    
    A <- n / total_train_size
    B <- min(1, runtime / hour)
    C <- 1 - accuracy
    points <- calculate_score(A, B, C)
    
    scoreboard <- rbind(scoreboard, data.frame(
      Model = "Neural Network",
      Sample_Size = n,
      Data = paste("dat", n, i, sep = "_"),
      A = round(A, dp),
      B = round(B, dp),
      C = round(C, dp),
      Points = round(points, dp)
    ))
  }
}
```

### Model 6: Random Forest, 100 Trees

Random Forests are ensembles of Classification Trees, where each tree is trained on a random subset of data and features. This model, using 100 trees, is expected to yield high accuracy due to its resilience to overfitting.

```{r code_model6_development, eval = TRUE}
# RF
# Function to train and evaluate Random Forest
run_random_forest <- function(sample_data, ntree = rf_ntree) {
  sample_data <- as.data.frame(sample_data)
  
  # Measure runtime for Random Forest
  start_time <- Sys.time()
  rf_model <- randomForest(label ~ ., data = sample_data, ntree = ntree)
  rf_predictions <- predict(rf_model, newdata = test_features)
  runtime <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  
  # Calculate accuracy and misclassification rate
  accuracy <- mean(rf_predictions == test_labels)
  return(list(accuracy = accuracy, runtime = runtime))
}

```

```{r load_model6}
# Apply Random Forest model to each sample size and iteration
for (n in n.values) {
  for (i in 1:iterations) {
    sample_data <- train[sample(.N, n)]
    result <- run_random_forest(sample_data, ntree = rf_ntree)
    accuracy <- result$accuracy
    runtime <- result$runtime
    
    A <- n / total_train_size
    B <- min(1, runtime / hour)
    C <- 1 - accuracy
    points <- calculate_score(A, B, C)
    
    scoreboard <- rbind(scoreboard, data.frame(
      Model = paste("Random Forest", "-", rf_ntree, " trees"),
      Sample_Size = n,
      Data = paste("dat", n, i, sep = "_"),
      A = round(A, dp),
      B = round(B, dp),
      C = round(C, dp),
      Points = round(points, dp)
    ))
  }
}
```

### Model 7: Random Forest, 500 Trees

By increasing the number of trees to 500, this Random Forest variation aims to improve stability and accuracy at the cost of increased computation time.

```{r code_model7_development, eval = TRUE}
# RF
# Function to train and evaluate Random Forest
run_random_forest <- function(sample_data, ntree = rf_ntree) {
  sample_data <- as.data.frame(sample_data)
  
  # Measure runtime for Random Forest
  start_time <- Sys.time()
  rf_model <- randomForest(label ~ ., data = sample_data, ntree = ntree)
  rf_predictions <- predict(rf_model, newdata = test_features)
  runtime <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  
  # Calculate accuracy and misclassification rate
  accuracy <- mean(rf_predictions == test_labels)
  return(list(accuracy = accuracy, runtime = runtime))
}

```

```{r load_model7}
for (n in n.values) {
  for (i in 1:iterations) {
    sample_data <- train[sample(.N, n)]
    result <- run_random_forest(sample_data, ntree = rf_ntree2)
    accuracy <- result$accuracy
    runtime <- result$runtime
    
    A <- n / total_train_size
    B <- min(1, runtime / hour)
    C <- 1 - accuracy
    points <- calculate_score(A, B, C)
    
    scoreboard <- rbind(scoreboard, data.frame(
      Model = paste("Random Forest", "-", rf_ntree2, " trees"),
      Sample_Size = n,
      Data = paste("dat", n, i, sep = "_"),
      A = round(A, dp),
      B = round(B, dp),
      C = round(C, dp),
      Points = round(points, dp)
    ))
  }
}
```

### Model 8: XGBoost

XGBoost is a powerful boosting algorithm that sequentially trains decision trees to minimize error. This model is optimized for speed and accuracy through parameter tuning, making it suitable for complex datasets.

```{r code_model8_development, eval = TRUE}

# xgboost
# Function to train and evaluate GBM using xgboost
run_gbm <- function(sample_data, max_depth = xgboost_max_depth, eta = xgboost_eta, nrounds = xgboost_nrounds) {
  # Prepare data for xgboost
  train_matrix <- xgb.DMatrix(data = as.matrix(sample_data[, -1, with = FALSE]), label = as.numeric(sample_data$label) - 1)
  test_matrix <- xgb.DMatrix(data = as.matrix(test_features), label = as.numeric(test_labels) - 1)
  
  # Set parameters for xgboost
  params <- list(
    objective = "multi:softmax",
    num_class = length(unique(train$label)),
    max_depth = max_depth,
    eta = eta
  )
  
  # Measure runtime for GBM
  start_time <- Sys.time()
  gbm_model <- xgboost(params = params, data = train_matrix, nrounds = nrounds, verbose = 0)
  gbm_predictions <- predict(gbm_model, test_matrix)
  runtime <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  
  # Calculate accuracy and misclassification rate
  accuracy <- mean(gbm_predictions == as.numeric(test_labels) - 1)
  return(list(accuracy = accuracy, runtime = runtime))
}
```

```{r load_model8}
for (n in n.values) {
  for (i in 1:iterations) {
    sample_data <- train[sample(.N, n)]
    result <- run_gbm(sample_data, max_depth = xgboost_max_depth, eta = xgboost_eta, nrounds = xgboost_nrounds)
    accuracy <- result$accuracy
    runtime <- result$runtime
    
    A <- n / total_train_size
    B <- min(1, runtime / hour)
    C <- 1 - accuracy
    points <- calculate_score(A, B, C)
    
    scoreboard <- rbind(scoreboard, data.frame(
      Model = "GBM",
      Sample_Size = n,
      Data = paste("dat", n, i, sep = "_"),
      A = round(A, dp),
      B = round(B, dp),
      C = round(C, dp),
      Points = round(points, dp)
    ))
  }
}
```

### Model 9: Multinomial Logistic Regression

Multinomial Logistic Regression is a generalized form of logistic regression suited for multiclass classification tasks. While less complex, this model is known for its interpretability.

```{r code_model9_development, eval = TRUE}
#Multinomial logistic regression
# Function to train and evaluate Multinomial Logistic Regression
run_multinomial_logreg <- function(sample_data) {
  sample_data <- as.data.frame(sample_data)
  
  # Measure runtime for Multinomial Logistic Regression
  start_time <- Sys.time()
  logreg_model <- multinom(label ~ ., data = sample_data, maxit = 200)
  logreg_predictions <- predict(logreg_model, newdata = test_features)
  runtime <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  
  # Calculate accuracy and misclassification rate
  accuracy <- mean(logreg_predictions == test_labels)
  return(list(accuracy = accuracy, runtime = runtime))
}
```

```{r load_model9}
for (n in n.values) {
  for (i in 1:iterations) {
    sample_data <- train[sample(.N, n)]
    result <- run_multinomial_logreg(sample_data)
    accuracy <- result$accuracy
    runtime <- result$runtime
    
    A <- n / total_train_size
    B <- min(1, runtime / hour)
    C <- 1 - accuracy
    points <- calculate_score(A, B, C)
    
    scoreboard <- rbind(scoreboard, data.frame(
      Model = "Multinomial Logistic Regression",
      Sample_Size = n,
      Data = paste("dat", n, i, sep = "_"),
      A = round(A, dp),
      B = round(B, dp),
      C = round(C, dp),
      Points = round(points, dp)
    ))
  }
}
```

### Model 10: Elastic Net Regression

Elastic Net Regression combines L1 and L2 regularization, balancing feature selection and model complexity. It is particularly effective in high-dimensional datasets where feature correlation is a concern.

```{r code_model10_development, eval = TRUE}
 #function to train and evaluate elastic net 

run_elastic_net <- function(sample_data, alpha = .5, lambda = NULL) {
  sample_data <- as.data.frame(sample_data)
  
  # Convert the label to a factor and then to numeric for glmnet compatibility
  sample_data$label <- as.numeric(as.factor(sample_data$label))
  
  # Extract features and labels
  features <- as.matrix(sample_data[, -1])  # All columns except the label
  label <- sample_data$label
  
  # Measure runtime for Elastic Net
  start_time <- Sys.time()
  
  # Fit the Elastic Net model
  en_model <- glmnet(
    x = features, y = label,
    alpha = alpha,
    lambda = lambda,
    family = "multinomial"  # Use multinomial for multiclass classification
  )
  
  # Use the best lambda chosen by cross-validation
  best_lambda <- en_model$lambda.min
  
  # Make predictions using the best lambda
  en_predictions <- predict(en_model, newx = features, type = "class", s = best_lambda)
  
  runtime <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  
  # Calculate accuracy (assuming en_predictions returns classes as numbers)
  accuracy <- mean(en_predictions == label)
  return(list(accuracy = accuracy, runtime = runtime))
}

```

```{r load_model10}
# Apply elastic model to each sample size and iteration
for (n in n.values) {
  for (i in 1:iterations) {
    sample_data <- train[sample(.N, n)]
    result <- run_elastic_net(sample_data = sample_data, alpha = .5)
    accuracy <- result$accuracy
    runtime <- result$runtime
    
    A <- n / total_train_size
    B <- min(1, runtime / hour)
    C <- 1 - accuracy
    points <- calculate_score(A, B, C)
    
    scoreboard <- rbind(scoreboard, data.frame(
      Model = "Elastic Net",
      Sample_Size = n,
      Data = paste("dat", n, i, sep = "_"),
      A = round(A, dp),
      B = round(B, dp),
      C = round(C, dp),
      Points = round(points, dp)
    ))
  }
}
```

## Scoreboard

```{r scoreboard}
# scoreboard is ordered by the points from lowest to highest (as we want the lowest points)
Preliminary_Results <- scoreboard[order(scoreboard$Points, scoreboard$Model, scoreboard$Sample_Size), ]
kable(Preliminary_Results)
```


```{r}
scoreboard <- scoreboard %>%
  group_by(Model, Sample_Size) %>%
  summarise(
    Mean_A = round(mean(A), 4),
    Mean_B = round(mean(B), 4),
    Mean_C = round(mean(C), 4),
    Mean_Points = round(mean(Points), 4)
  ) %>%
  arrange(Mean_Points)
kable(scoreboard)
```


## Discussion

In evaluating the models, we focused on three key criteria: sample size proportion (A), runtime as a fraction of an hour (B), and misclassification rate (C). These criteria were used to generate a cumulative score, where lower scores indicate better performance.

The Random Forest model with 100 trees stands out as the best-performing model in this analysis due to its balanced combination of accuracy, runtime efficiency, and scalability. Across various sample sizes, Random Forest maintained a low misclassification rate and a short runtime, making it both accurate and computationally feasible for larger datasets.

## Model Development Responsibilities

For the 10 models, please list the names of the developers along with percentages for how the responsibilities were divided.

1.  KNN - Martin
2.  Classification Tree - Martin
3.  SVM, cost = 1 - Martin
4.  SVM, cost = 10 - Martin, Michelle
5.  Neural Nets - Fangran
6.  Random Forest, 100 Trees - Tatiana
7.  Random Forest, 500 Trees - Tatiana, Michelle
8.  XGBoost - Tatiana
9.  Multinomial Logistic Regression - Fangran
10. Elastic Net Regression - Michelle
